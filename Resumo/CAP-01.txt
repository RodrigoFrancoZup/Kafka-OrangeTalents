Capítulo 01 - Produtores e consumidores
Nesse capítulo aprendemos:

⦁	Vamos entender o que é Mensageria e Kafka:
	Vamos pensar em um sistema de e-commerce (usuário vai fazer uma compra), teremos o usuário (navegador) requisitando o servidor HTTP e o servidor irá começar o processo.
	Esse processo pode ser feito de algumas maneiras:
 
I) O servidor pode fazer todo o processamento de compra sozinho (somente ele), em um único serviço (uma linha de código abaixo da outra). Esse processo de compra  exige diversas tarefas, como verificar fraude, enviar email ao cliente, abater estoque, etc.  Essa maneira aumenta a espera, pois as atividades passam a ter ordem, para atividade 2 começar tem que esperar a ativadade 1 terminar e assim por diante...(Nesse modelo temos apenas caixinha)

II) A outra maneira seria dividir cada processo da compra (verificar fraude, enviar email ao cliente, abater estoque) em serviços distintos, essa maneira permite realizar algumas atividades ao mesmo tempo, por exemplo ao receber o pedido de compra o nosso serviço dispara o e-mail de confirmação e começa a verificação de fraude ao mesmo tempo. Essa abordagem permite deixar cada serviço rodando em máquinas distintas ou a mesma maquina usando outra thread (cada thread executa um serviço). O problema dessa abordagem é quando a quantidade de serviços começam a crescer,  pois começa aumentar a dependência de um serviço com outro, ou seja, um serviço tem que comunicar com outro, um sistema conhece outro sistema, e isso piora quando colocarmos um sistema de Logs e de Analytcs (todos os outros serviços precisam conversar com esses dois), a bagunça começa aqui (lembra dos modelos, a quantiade de setinhas só crescendo). Outro problema agora é, se um serviço começa a depender do outro o que acontece se um serviço parar de funcionar? Vai travar o outro sistema, e todo o dado que estava no sistema que parou foi perdido...(Nesse modelo temos várias caixinhas, há comunicação entre elas que são representadas por muitas setinhas)
Obs: Sistema de log é registrar tudo que cada serviço está fazendo e Analytcs é obter dados  (métricas) do tipo: quantas fraudes ocorreram? O serviço X ta caindo quantas vezes? Quantos e-mails estão indo e voltando (erro)? O tempo de geração de NF ta alto?

III) Outra forma é aplicar a Mensageria, que é criar uma camada (broker) antes dos serviços, no caso o usuário vai requisitar uma compra ao servidor HTTP e o servidor HTTP vai informar (enviar mensagem) ao Broker informando que surgiu um pedido de compra (o broker agora tem os dados exigidos para se fazer um compra), os serviços de enviar email, verificar fraude, abater estoque vao passar a ouvir o Broker, ou seja, o serviço de email, fraude e estoque não precisam se conhecerem mais, não há comunicação entre eles, todos os serviços agora passam apenas a ouvir e comunicar-se com o Broker. Vou apresentar algumas vantagens dessa abordagem, algumas são vantagens da mensageria e outras da implementação do Kafka: 
A) podemos configurar o que cada serviço (caixinha) deve ouvir (qual mensagem ele deve levar em consideração) e o que ela irá escrever no broker. Vantagem da mensageria; 
B) Cada serviço e até mesmo o broker podem estar em diversas máquinas, se uma cair eu tenho outra - redundancia. Vantagem da mensageria;
C) Os serviços podem ser configurados para rodarem em paralelo, mas eu posso configurar também que um serviço execute de maneira diferente quando o envolvido for um determinado usuário, ou para um determinado produto (exemplo, usuario X cometeu fraude eu não vou executar mais compras dele, ou então, só vou reservar estoque pra esse usuário quando o pagamento for aprovado, pois ele já deu golpe, deixando assim a execução de forma sequencial para ele...) -Vantagem do Kafka.
(Nesse modelo há diversas caixinhas, mas não há comunicação "setinhas" entre elas, as setinhas agora saem do serviço em direção ao Broker. Um serviço escuta o broker e também pode escrever outra mensagem no broker);

⦁	Instalando o Kafka localmente:
1.	Acessar o site https://kafka.apache.org/downloads e baixar o tipo Binary Downloads, na versão mais nova disponível, no meu caso foi: Scala 2.13  - kafka_2.13-2.8.0.tgz (asc, sha512);
2.	Descompactar o arquivo baixado (as vezes temos que fazer esse passo duas vezes, a primeira descompactação gerará um arquivo .tar, e ao descompactar o .tar teremos as pastas). Agora temos a pasta kafka;
3.	Dica, de preferência em deixar a pasta kafka em um path sem palavras com espaços;
4.	O Kafka para funcionar exige um local de armazenamento, podemos usar o Zookeeper para isso, e essa ferramenta já vem com Kafka, precisamos apenas levantar o zookeeper primeiro, para depois levantar o Kafka.

⦁	Rodando o Kafka pelo terminal:
1.	Vamos levantar o Zookeeper: para isso temos que entrar via terminal e FICAR na pasta kafka e executar o .\bin\windows\zookeeper-server-start.bat juntamente com a configuração padrão .\config\zookeeper.properties. (Estaremos usando sempre o .bat e "\", pois estamos no ambiente windows, no linux seria o .sh, não precisariamos entrar na pasta windows e a barra seria "/"). O comando executado nesse passo foi: .\bin\windows\zookeeper-server-start.bat .\config\zookeeper.properties. Zookeeper agora esta rodando na porta 2181  e não podemos fechar seu terminal;
2.	Podemos agora levantar o Kafka, não podemos fechar o terminal que ta rodando o Zookeeper. Em um novo terminal, na pasta kafka executar: .\bin\windows\kafka-server-start.bat .\config\server.properties. Kafka agora ta rodando na porta 9092 e não podemos fechar sua janela (terminal);
3.	Vamos agorar criar um tópico para podermos trocar mensagem, para isso na pasta kafka vamos rodar o comando: 	.\bin\windows\kafka-topics.bat --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic LOJA_NOVO_PEDIDO. Vamos entender esse comando, estamos indicando que vamos manipular um topico (kafka-topics.bat), a ação é criar (--create), vamos indicar onde vamos criar, no caso (bootstrap-server rodando no localhost:9092), --replaction e --partition são propriedades do tópico, vamos ver depois, e vamos dar um nome ao tópico com o comando --topic NOME_DO_TOPICO (o recomendavel é usar "." ou "_" para nome composto;
4.	Verificar se o topico foi criado, podemos digitar no mesmo terminal utilizado no item anterior o comando:  .\bin\windows\kafka-topics.bat --list --bootstrap-server localhost:9092. Note que o comando é na seção de kafka-topics, o comando é --list e é preciso falar onde o kafka está rodando;
5.	Enviar mensagem para esse tópico: vou deixar o terminal do item anterior (3 e 4) para manipular o topico, para enviar mensagem vou criar um novo terminal e digitar o comando: .\bin\windows\kafka-console-producer.bat --broker-list localhost:9092 --topic LOJA_NOVO_PEDIDO. Após esse comando cada linha digitada no terminal será uma mensagem enviada, por exemplo (pedido1,500),(pedido2,700), (pedido3,1000), onde o conteudo de cada () foi digitado em uma linha sem o "()" e em cada linha foi dado "enter". Nesse comando usamos o producer para criar um produtor de mengagem, indicamos onde está rodando com --broker-list, indicamos qual tópico.
6.	Agora vamos ouvir essas mensagens, em um novo terminal vou digitar: .\bin\windows\kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic LOJA_NOVO_PEDIDO (ESSE COMANDO COMEÇA OUVIR AGORA, NÃO TERÁ MENSAGEMS ANTIGAS, SOMENTE MENSAGEM QUE VAI SER CRIADA DE AGORA A DIANTE) Para pegar as mensagens antigas: .\bin\windows\kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic LOJA_NOVO_PEDIDO --from-beginning. Nesse comando usamos o console-cosumer, indicando que vamos consumir o topico e será no console, indicamos pelo --bootstrap o local onde está rodando, pelo --topico indicamos qual topico queremos ouvir, e --from-beginning indica que queremos mensagens passadas também.

⦁	Resumos de conceito até aqui, produtor (Producer) é que envia a mensagem, consumidor (Consumer) é quem consultar a mensagem. Criamos um tópico no Kafka para "armazenar" as mensagens, é a "caixa de entrada";

⦁	Criando Produtores em Java:
1.	Criar um projeto Java do tipo Maven (GoupId = br.com.rodrigo e ArtifactId=ecommerce);
2.	No arquivo pom.xml adicionar a dependência do Kafka Clients:

<dependency>
	<groupId>org.apache.kafka</groupId>
	<artifactId>kafka-clients</artifactId>
	<version>2.8.0</version>
</dependency>             

3.	Adicionar no pom.xml a dependência do Log sl4j simple:

<dependency>
	<groupId>org.slf4j</groupId>
	<artifactId>slf4j-simple</artifactId>
	<version>1.7.30</version>
</dependency>                 

4.	Criar a classe NewOrderMain (uma classe main para exemplificar o novo pedido de compra). Criar nessa classe o método main();
5.	A classe vai ficar com o conteudo:

/*
Levantar o Zookeeper;
Levantar o Kafka
 */
public class NewOrderMain {

    public static void main(String[] args) throws ExecutionException, InterruptedException {

        //Criando um producer com chave em string e valor em string (uma mensagem é feita de chave e valor)
        //Precisamos de um properties, ou seja, uma configuração. Podemos criar aqui ou ler de um arquivo.

        var producer = new KafkaProducer<String,String>(properties());

        //Criando esse valor para ser chave e valor (conteudo) da mensagem. Para teste podem ser iguais.

        var value = "159357,456789,741963258";

        //Criando a mensagem, o seu primeiro parâmetro é o tópico: ECOMMERCE_NEW_ORDER, depois vem chave e valor.

        var record = new ProducerRecord<String, String>("ECOMMERCE_NEW_ORDER", value, value);

        //Enviar mensagem
        //O método .send não é blocante (ele executa no futuro), ele é assíncrono, não fica esperando. Por isso colocamos após o .send() o .get()
        //Com .get() forço a espera!
        //Dentro do send coloco a mensagem que quero enviar ao Kafka (record)
        //Dentro do .send() coloco um callback (data,ex), com ele poderemos obter respostas se a mensagem criada deu certo ou não

        producer.send(record, (data, ex) ->{
            if(ex != null){
                return;
            }
            //Se der certo vai rolar o print:
            System.out.println("Sucesso enviando "+ data.topic() + ":::partition " + data.partition() + "/ offset " + data.offset() + "/" + data.timestamp());
        }).get();
    }

    //Criando as configurações do Producer

    private static Properties properties() {
        var properties = new Properties();

        //Indico onde vamos nos conectar, onde está rodando o kafka

        properties.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "127.0.0.1:9092");

        //Aqui indico o serializador da chave, se minha chave é String preciso de serializador de String
        //Nesse caso o serializador vai pegar a String da chave e transformar em bytes;
        
	properties.setProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());

        //Aqui indico o serializador do valor, se valor é String preciso de serializador de String
        //Nesse caso o serializador vai pegar a String do valor e transformar em bytes;
        
	properties.setProperty(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        return properties;
    }
}

⦁	Criando o Consumidores em Java:

1.	Vamos criar um consumidor, esse será um serviço que verifica se a compra é fraude ou não. Vamos criar a classe: FraudDetectorService. Criar nessa classe o método main();

2.	O conteudo da classe será:

/*
Levantar o Zookeeper;
Levantar o Kafka
 */
public class FraudDetectorService {

    public static void main(String[] args) {

        //Criando um consumer, que consumirá mensagem com chave em string e valor em string
        //Precisamos de um properties, ou seja, uma configuração. Podemos criar aqui ou ler de um arquivo.

        var consumer = new KafkaConsumer<String, String>(properties());

        //Indico  qual tópico vou consumir as mensagens, normalmente escolhemos só UM,
        // Por parâmetro passo uma Collection qualquer e o Nome do Tópico que vou escutar

        consumer.subscribe(Collections.singletonList("ECOMMERCE_NEW_ORDER"));

        // Vou manter isso em looping infinito para ficar ouvindo sempre!

        while(true) {

            //.poll() é para meu consumidor ficar perguntando se tem mensagem, ficar ouvindo, passo um tempo de duração,
            //as mensagens que eu escutar vai cair na variavel records

            var records = consumer.poll(Duration.ofMillis(100));

            //Verifico se há mensagens, se tiver vou mostrá-las!

            if (!records.isEmpty()) {
                System.out.println("Encontrei " + records.count() +  " registros");
                for (var record : records) {
                    System.out.println("=========================================");
                    System.out.println("Processando novo pedido, checando fraude!");
                    System.out.println(record.key());
                    System.out.println(record.value());
                    System.out.println(record.partition());
                    System.out.println(record.offset());
                    try {
                        Thread.sleep(5000);
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                    System.out.println("Pedido processador");
                }
            }
        }
    }

    //Criando as configurações do Consumer

    private static Properties properties() {
        var properties = new Properties();

        //Indico onde vamos nos conectar, onde está rodando o kafka, onde vamos escutar

        properties.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "127.0.0.1:9092");

        //Aqui indico o deserializador da chave, se minha chave era String preciso de deserializador de String
        //Nesse caso o deserializador vai pegar a chave que esta em bytes e transformar em String;

        properties.setProperty(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());

        //Aqui indico o deserializador do valor, se meu valor era String preciso de deserializador de String
        //Nesse caso o deserializador vai pegar o valor que esta em bytes e transformar em String;

        properties.setProperty(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());

        //Estou colocando esse serviço em um grupo (dei ao grupo o nome da classe)
        //Adicionar um serviço em grupo, garante que esse serviço receberá todas as mensagens que ele está ouvindo

        properties.setProperty(ConsumerConfig.GROUP_ID_CONFIG, FraudDetectorService.class.getSimpleName());
        
        return properties;
    }
}

⦁	Pergunta do capítulo: Em um sistema bancário, um usuário inicia o processo de uma transação bancária, qual abordagem é baseada em produtores e consumidores de mensagens? Resposta: A requisição é feita por um site ou app cujo servidor envia uma mensagem de pedido de transação bancária. (Essa abordagem mistura o processo síncrono e a mensagem.)